# Attribution Reporting API

May 3, 2021

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Use Google meet “Raise hand” for queuing


# Agenda



*   Introductions
*   Scribe volunteer: Erik Taubeneck
*   [Criteo ML challenge](https://github.com/WICG/conversion-measurement-api/issues/137)
*   New proposals
    *   [Cross device doc](https://github.com/WICG/conversion-measurement-api/blob/main/cross_device.md)
*   Any other business
    *   Jonasz (RTB House): aggregate reporting in Turtledove ([https://github.com/WICG/turtledove/issues/93#issue comment-780682526](https://github.com/WICG/turtledove/issues/93#issuecomment-780682526))
    *   Blind signatures (PCM)


# Attendees — please sign yourself in! 



1. Mikko Juola (NextRoll)
2. Charlie Harrison (Chrome)
3. Brian May (dstillery)
4. Andrew Pascoe (NextRoll)
5. Valentino Volonghi (NextRoll)
6. Larissa Licha (NextRoll)
7. Basile Leparmentier (Criteo)
8. Marçal Serrate (Hybrid Theory)
9. Michael Kleber (Chrome)
10. Erik Taubeneck (Facebook)
11. Andrew Knox (Facebook)
12. Jonasz Pamuła (RTB House)
13. Brendan Riordan-Butterworth (IAB Tech Lab / eyeo GmbH)
14. Vincent Grosbois (Criteo)
15. Marshall Vale (Chrome)
16. John Delaney (Google Chrome)
17. Benjamin Case (Facebook)
18. Abdellah Lamrani Alaoui (Scibids)
19. Daniel Rojas (Google Chrome)
20. Lorenzo Hernandez (NextRoll)
21. Alois Bissuel (Criteo)


# Notes



*   Criteo ML Challenge
    *   Basile: Some overlap with the web-adv meeting announcement. Criteo is going to do a challenge for ML with DP. This is how we understand how delivery will work with FLEDGE. There is one use case which is quite new: optimization. Running ML models so that the advertising we do is as precise as possible. It’s important because it improves advertiser performance and publisher revenue. The pitch is to target advertisements in an optimized form, starting next Monday. We are setting up the challenge which will provide a DP report along with non-private data so that you can iterate. This will allow folks who join the challenge to get started. There will be two data sets, a small one and a big one which will be aggregated. There will be a prize, so the data will be quite constrained to avoid cheating. This is why I’m talking about it today, it would be great if you could provide us with an epsilon. At the end we will release the full dataset. We need just one epsilon so that we can limit the number of choices. The idea is really to learn how to work with aggregated data. Also to learn what is the impact of different types of noise on the performance. We are starting with click data, so that the first challenge is a bit easier. We understand that whatever epsilon we use is non-binding. For the noise type, we’re working with Gaussian, so it’s delta-epsilon private.
    *   Charlie: Don’t have an answer (on epsilon) right now, but working on a doc that should have everything you need. Hope we can get it to you in the next couple days.
    *   Brian: Just wondering if that document will be generally available.
    *   Charlie: Yes, document or post on github issue will be public.
    *   Charlie: Couple questions: One thing you mentioned is that since you pre-aggregated the data, you’ve fixed the query. Do you think it could be more flexible is people wanted more flexibility, you could provide an API that would provide other queries.
    *   Basile: Because it’s a challenge setup at KDD, if you want people outside this group, we had simplicity to consider. There was a concern that some may cheat to win the prize, so we wanted to make it as simple as possible in order for people not to cheat.
    *   Charlie: One other quick question: In terms of the goal of the challenge, for this big dataset. I assume we have hidden labels and need to predict that a particular ad creative was clicked.
    *   Basile: The goal will be predicting the click, but we are also interested in predicting sale. The prize will just be for click for simplicity.
    *   Abdellah: Is there a goal to see performance at a certain threshold with a given epsilon?
    *   Basile: We’ll have a benchmark, but the challenge is to see performance as high as possible.
    *   Abdellah: When will you open this up?
    *   Basile: Starting next week. August 15th is when the full data will open up.
    *   Abdellah: I was worried we’d get the results quite late. It’s important to know how the epsilon parameter will perform.
    *   Basile: The idea isto only measure the impact of epsilon. Right now we have granular data, but only having aggregated data will change how models work. So we are interested in epsilon impact, but also new way to learn models on this aggregated data.
*   Measuring conversions across devices
    *   Charlie: 
        *   This is a topic that came up ~a year ago in web-adv. I know Facebook had also come up with a proposal. We have a somewhat simpler design that we wanted to get some feedback on. We could facilitate this using the browsers sign-in mechanism. If we could leverage this, browsers could learn each other and communicate events between them.
        *   The challenge is that we don’t address cases that span multiple identity providers.
        *   The way it would work, you’d opt-in (on the API site) to this on the attribution source side by adding a new element, and on the trigger side by a new query param.
        *   Reports would change on the event level with a new boolean which shows if it’s cross device. For aggregate, we’d allow this to be used as an aggregation key.
        *   In terms of implementation, we’re exploring two. One is an E2E encrypted channel, similar to the Facebook proposal. Each browser would have a public key, and the browser vendor would sync those public keys between logged in session. Similar to some features that are implemented in Chrome right now (copy/paste across devices, send phone number from desktop to phone, etc.)
        *   Other design is server-side storage, encrypted at rest. This is more similar to something like a syncing service. If we went with this route, we’d want to make sure the browser vendor has minimal insight into the data. This addresses coverage issues like adding new devices.
    *   Brendan
        *   Listening to this, you’re basically storing conversion data against a user_id or email address, it does seem similar to UID2.0. (Here in context of IAB TL.) Curious if there is consideration for other publisher based ID system.
    *   Charlie
        *   This is in the alternatives section. One way to look at this is as an intermediate solution, and something that would work with other identity proposals across browsers is a good goal.
    *   Brian
        *   Just wondering if the intent was to provide a single as to if cross device was available when the impression happened.
    *   Charlie
        *   Probably not, since that would leak some information about the user being logged in. If that tag was set, it would be considered “best effort.” Would you say knowing beforehand would be critical?
    *   Brian
        *   It’s easier to know what you’re working with.
    *   Charlie
        *   We can explore it if it’s useful.
    *   Erik
        *   Would not be able to work cross browser.
    *   Charlie
        *   This is a known issue. Thinking about this as a simplest to pull off solution. I don’t think we’d stop there. Having something that supports many identity providers, especially if that works across vendors, would be nice to support in the long term.
    *   Brian
        *   I agree with that. People signing into multiple browsers without picking up the data.
*   Aggregate Reporting in TURTLEDOVE
    *   Jonasz
        *   There are a number of issues that the current reporting mechanism isn’t enough for a number of use cases. One of which is optimization of bidding models. It was mentioned that this was a better forum to discuss this.
        *   The “report win” (proposed mechanism for reporting) does not have access to all the bidding signals. 
    *   Charlie
        *   Don’t have a great answer for you today, but we are working on a proposal for how a generic aggregate reporting mechanism could work (instead of just conversion reporting.) I think that’s how this “report win” function could work. The function could have access to all the signals, and then submit that to the aggregation API which would allow aggregates out of that.
    *   Jonasz
        *   What is the timeline you propose from getting from the proposal to a working system? Will it be available before 3PC are dropped?
    *   Charlie
        *   Just to be clear, you’re looking for something get aggregates on conversions.
    *   Jonasz
        *   For the purpose of this, we can think about optimizing on clicks.
    *   Charlie
        *   For conversion, we will have something in this repo so stay tuned. You could submit in the worklet, and later you’ll be able to get aggregate report on conversions. The thing that may take longer is this generic system. The biggest difference here is just API surface. We are hoping to have this before 3PC are deprecated.
    *   Jonasz
        *   What is the level of coordination between this mechanism and FLEDGE?
    *   Charlie
        *   We definitely have the FLEDGE timeline in mind. For the initial experiment, there is the event level reports which should mitigate this loss. We’re definitely working on this as fast as we can.
    *   Jonasz
        *   This is the problem, the temporary mechanism is not enough.
    *   Basile
        *   Fully agree with Jonasz. We don’t have user level data. If we do this we’ll have to fully rely on data that comes from elsewhere. Potentially we could have “report win” with k-anonymity.
    *   Charlie
        *   Thanks for the feedback. We’ll take it to heart and get back to you.
    *   Jonasz
        *   One important step would be to update the FLEDGE specification with this. Even the basic models we'll use at the beginning will take months to research and design.
    *   Valentino
        *   Wanted to attach myself to this conversation. With a real time feedback with small noise sent back to the DSP, if that could be specified, that would be great. It’s a pretty critical piece of functionality.
    *   Charlie
        *   You’ve opened an issue on this?
    *   Valentino
        *   Going to open it today. FLEDGE or Conversion Measurement API?
    *   Charlie
        *   Open it in FLEDGE but tag me.
*   Blind signatures in the event level API
    *   Reports are sent to a wide open URL on the publisher /advertiser web site
    *   Can’t authenticate that without removing privacy protections
    *   This is a bigger issue on PCM (8 bits), maybe less of an issue on event-level measurement
    *   In 2019 we came up with using blind signatures, sign it but thing you sign is blinded
    *   In the end, can use cryptography to validate it is a signature you signed, but unlinkable to the original
    *   Potentially compatibility issues with event-level + PCM
        *   Event-level → fake conversion
    *   Issue on [PCM](https://github.com/privacycg/private-click-measurement/issues/41) and a session in the privacy CG face to face.
*   Brian → Link to add to the chat?