# Attribution Reporting API

May 17, 2021

Meet link: [https://meet.google.com/jnn-rhxv-nsy](https://meet.google.com/jnn-rhxv-nsy)

Use Google meet “Raise hand” for queuing


# Agenda



*   Introductions
*   Scribe volunteer: Maud Nalpas
*   Aggregate attribution reports [doc update](https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md)
    *   Worklet processing model
    *   Fixed domain + prefix queries
    *   User contribution budgeting on the client
    *   MPC optional
*   Compute affiliate commissions based on conversions value #147
    *   [https://github.com/WICG/conversion-measurement-api/issues/147](https://github.com/WICG/conversion-measurement-api/issues/147)
*   Meta feedback
*   Any other business


# Attendees — please sign yourself in! 



1. Charlie Harrison (Chrome)
2. Brian May (dstillery)
3. Andrew Knox (Facebook)
4. Erik Taubeneck (Facebook)
5. John Delaney (Chrome)
6. Aleksei Gorbushin (Walmart)
7. Saurabh Shah (Walmart)
8. Larissa Licha (NextRoll)
9. Abdellah Lamrani Alaoui (Scibids)
10. Benjamin Case (Facebook)
11. Przemyslaw Iwanczak (RTB House)
12. Valentino Volonghi (NextRoll)
13. Brendan Riordan-Butterworth (IAB Tech Lab / eyeo GmbH)
14. Basile Leparmentier (Criteo)
15. Andrew Pascoe (NextRoll)
16. Matt Zambelli (Neustar)
17. Erik Anderson (Microsoft)
18. 
19. Viraj Awati (Amazon)
20. Maud Nalpas (Chrome)
21. Aloïs Bissuel (Criteo)


# Notes



*   Introductions
*   Aggregate attribution reports [doc update](https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md)
    *   Worklet processing model
    *   Fixed domain + prefix queries
    *   User contribution budgeting on the client
    *   MPC optional
*   Compute affiliate commissions based on conversions value #147
    *   [https://github.com/WICG/conversion-measurement-api/issues/147](https://github.com/WICG/conversion-measurement-api/issues/147)
*   Meta feedback
*   Any other business


## Intros


## Aggregate attribution reports doc update

Charlie Harrison:



*   The changes collapse a lot of discussions we had into one doc.
*   The biggest changes are for an OT, we're interested in BYOS model: anyone can participate in this trial, you can try your own implementation for an agg server.
*   Goal is to have as many people as possible testing these out.
*   Going alone with that, MPC is positioned as an end-state. But for an initial experiment, in the short-term, that's optional. You can use a implementation that's accessible.

Erik Taubeneck:



*   Is the underlying algo a single-party algo?
    *   Charlie Harrison: You can test both algos. The reason is twofold:
        *   MPC complexity
        *   We're not sure the algo will scale 

Charlie Harrison:



*   New method to craft reports using JS; this is what we discuss as a worklet-style API. Instead of triggering conversion with HTTP req, you invoke JS that then gets access to event-level info on both sides (in the clear **but **in an isolated worklet model).
*   The way this work is via a new param to impressions (attribution sources). It can contain anything about the impression; even higher entropy than 64 bits. It can contain e.g. campaign ID, structured data e.g. comma separated list. The entropy of this field is not load-bearing on a privacy level. The limitation is just for storage.
*   On the attribution trigger side, we have a similar approach. We'd use this snippet (demoes code snippet) to register a JS file that's responsible for configuring how conversion works. Then that's invoked via the function.
*   You can also distinguish view vs click via sourceType.
*   Final output: histogram contributions → histogram. Use these context items to define a histogram contribution i.e. a key-value pair that's (bucket, value).
*   Output: histogram contribution across the same type.
*   Reports look like: 
    *   See [https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md#aggregate-attribution-reports](https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md#aggregate-attribution-reports) 
    *   Privacy Budget: to avoid ata stuffing and repeating queries
    *   scheduled_report_type: provided because this may be used for the PB

Basile Leparmentier:



*   Criteo considered; will we have thousands of source sites ie millions of source sites?
*   Same Q on attr destination
*   If we want to query on a publisher, it'd be great to query on all advertisers/publishers.
*   How would this work?
*   Charlie Harrison:
    *   The source site is the top level eTLD+1 of the site the user engaged with the ad. I.e. news.example. Same for attribution destination e.g. shoes.example.
    *   The reasoning is exactly for the reason you said; if you didnt provide this info to you, you'd need to query across all publishers or across all advertisers (you'd need to encode that in a key/bucket)

Basile:



*   How is noise computed? Unusable for advs and publishers? Are these 2 keys in clear on top of the big buckets, or is it something else?
*   Charlie Harrison:
    *   Privacy should be a tuple of 
    *   These will be separate units of privacy, so diff publishers would get diff PB
    *   PB will be partitioned by pub, adv pairs

Basile: 

CTR per publisher? You'd need to do that across all advertisers. If you're on smallsite.com (huge chunk of the open web) then you'd need to compute a CR across all partners, then the noise will scale. This is concerning. So I won't be able to have any reporting except on the big publishers.

Charlie Harrison:



*   So you want to combine these reports across these tuples?

Basile Leparmentier:



*   Yes

Charlie Harrison:



*   We can allow you to query without adding noise to these different partitions. We can bound the privacy budget for each partition by limiting the user contributions.
*   This doesn't stop you from grouping all these reports together, with only one noise.

Basile Leparmentier:



*   So I could query everything, and then you'd add the final noise?

Charlie Harrison:



*   Yes, and that model still has privacy protections.

Basile Leparmentier:



*   Not 100% clear on how the privacy budget will work across this 

Erik Taubeneck:



*   Relying on eTLD+1 will only escalate issue on the PSL (public suffix list)

Charlie Harrison:



*   Do you have any suggestions?

Erik Taubeneck:



*   We're trying to constitute a standard in "What's a business unity", this is hard, FPS are trying to do the same thing.
*   Different Q: when you trigger an attribution, how are sites considered for attribution?

Charlie Harrison:



*   Works like the EL API. The attribution algorithm looks at all the source events that share the reporting origin and advertiser site. On-device attribution algo is last touch. Now there's the option to do something a little more complicated, with priorities.

Erik Taubeneck:



*   So with processAggregate?

Charlie Harrison:



*   You can't pick in a programmatic way; we're looking into it. But it has privacy risks: then you'd end up with a JS environment that has a join between potentially a lot of sites 

Erik Taubeneck:



*   What prevents calling this f individually with a one extra bit that says whether that was the last touch or not? Would that mitigate the privacy risk?

Charlie Harrison:



*   Maybe, there are several ways to mitigate this. Ideally we'd move to something that's flexible and privacy-preserving. We're looking into this.

Erik Taubeneck:



*   Your concern is if the JS would leak the value? What's the threat model?

Charlie Harrison:



*   Worst case thing you can link is the join between the two contexts, and if you have more contexts, that makes it all more risky.

Erik Taubeneck:



*   If the worklet breaks, isn't it game over?

Charlie Harrison:



*   Right now you'd only see the last event, you'd learn one pair, not the whole list.
*   But yes, it'd be hard if the worklet broke.
*   We're looking into the web security of this.
*   Moving on to PB.
*   Each histogram contribution has a value attached to it e.g. purchaseValue, account.
*   The budget is in 2 pieces:
    *   One on the client
    *   One on the agg server
*   We're trying to push a lot of this on the client.
*   The browser is counting locally how much value has a user contributed to a histogram for the tuple. This partition defined the sensitivity of the histogram. If the user goes above this contrib limit, we'll drop reports.

Basile Leparmentier:



*   We talked about that, we said there'd be no user-level bounding 

Charlie Harrison:



*   We originally had both bounds; one was capping how much any given record can contribute, the other was capping how much any given report can contribute.
*   But then you'd be wasting budget
*   We're open to feedback on this

Basile Leparmentier:



*   Not sure this is 100% true, but maybe it is.
*   We're talking about one request. I don't see how I can do multiple requests. How does it work when you have multiple questions?

Charlie Harrison:



*   Ask x questions about a record: 
    *   When listing the histogram contribs, you're doing that upfront.
    *   A bucket is e.g. campaign, one is geolocation... For all these slices, you'd generate this upfront for multiple histogram contributions. Each record contributes to multiple keys.
    *   Participate in 200 buckets and ask one question

Basile Leparmentier:



*   What will we sent back? I don't understand.

Charlie Harrison:



*   If you have 8 agg keys
*   One event contributed to all 8
*   


Basile Leparmentier:


*   Our data is not hierarchical. I have two trees, advertiser and publisher… I'm confused, our data is not hierarchical.

Charlie Harrison:



*   Let's take a step back. Hierarchy is just another level of flexibility. You don't have to use it.
*   List of bucket and value pairs, and you have a million such buckets.
    *   Buckets = campaigns or bucket

Basile Leparmentier:



*   What's a bucket?

Charlie Harrison:



*   In this example, we have a million buckets, your number between 0 and million minus one
*   2 power 32 (4 billion) but probably less — but maybe all of them
*   If you have a million bucket your keys are 0 to a million
*   You'll get by default when you query the servers, a histogram that gives you each histogram index and the sum of the values plus some noise added to each bucket.
*   You get a million buckets back (plus some noise)
*   Note: we've added hierarchy to make it easier to work with very sparse domains (when most entries are 0)

Basile Leparmentier:



*   If I have 0 buckets which are the same
*   On the same buckets I'll have the same noise?

Charlie Harrison:



*   No
*   A user can max contribute will be caped to the sensitivity
*   So your 10 keys will need to share that budget
*   The noise will be shared 

Basile Leparmentier:



*   OK, understood
*   Still, I think the noise level will be way too high at least for the way we intend to use it at Criteo.
*   The challenge will be useful

Charlie Harrison:



*   Feel free to file an issue, happy to discuss this

Basile Leparmentier:



*   Let's see what the perf is. Maybe it'll be good, maybe not.

Valentino Volonghi:



*   It would be a good idea to add some real world examples of what you are trying to achieve here as opposed to just the technical background. For example what extreme cases look like or the ideal case you are optimizing for. In particular when connected to size of audience, number of queries and type of reporting coming back.

Charlie Harrison:



*   We'll add an example


## Affiliate

Marcos Broinizi:

We have advs not part of our domain

After the user clicks he's redirected to adv site

If he reaches the checkout

We have to pay a commission spent exactly by the user

The info we need is to know from each affiliated site how much value was generated by each site. We have many different affiliated sites

Charlie Harrison:



*   The tricky thing is you want a function of the purchase value
*   You want to aggregate that across users with little noise
*   The biggest issue with the noise is that it's tied to a $ value. If there's a lot of noise you may over or underpay.
*   If the noise amount is known upfront, you can consider include it in your calculation. Do you think that formalized noise could be handles in a business relationship?

Marcos Broinizi:



*   Yes I think so, if it's really limited to some amount and clear.

Charlie Harrison:



*   We should be able to do that
*   Concern: How big do those aggregate really get
*   If it's only like 3 users, you relative error could get very high (vs. 500 users)

Marcos Broinizi:



*   This may be an issue. We have a lot of cases where we have 2-3 purchases.

Charlie Harrison:



*   That's an area for us to focus on, so we know the API falls short in this case.